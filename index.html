<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
	<link rel="stylesheet" type="text/css" href="style/style.css">
    </style>
    <link rel="icon" type="image/png" href="img/jhu.png">
    <title>Enayat Ullah</title>
    <script src="js/scramble.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-52314772-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-52314772-2');
</script>

<!-- Default Statcounter code for homepage
enayatullah.github.io -->
<script type="text/javascript">
var sc_project=10773133; 
var sc_invisible=1; 
var sc_security="652f6d14"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/10773133/0/652f6d14/1/"
alt="Web Analytics"></a></div></noscript>
<!-- End of Statcounter Code -->


    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
    });
    </script>
    <script type="text/javascript" async
     src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>   
     <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script> 
     <!-- <link href='http://fonts.googleapis.com/css?family=Literata:400,700,400italic,700italic' rel='stylesheet' type='text/css'> -->
  </head>
  <body>
    <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
      <tr>
        <td>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="67%" valign="middle">
                <p align="center">
                  <name>Enayat Ullah</name> </br>
                  </font>
                  <!-- &nbsp &nbsp <a href="mailto:enayat@jhu.edu">enayat@jhu.edu</a>  -->
                  <!-- <b>email</b>: -->
          <font id="covermail"><font id="email" style="display:inline;">
            <noscript><i>Please enable Javascript to view.</i></noscript>
          </font></font>
          <script>
          emailScramble = new scrambledString(document.getElementById('email'),
              // 'emailScramble', 'ranasduke@pincer.not',
              'emailScramble', 'ayant  e @ju.edh   u',
              [3,4,5,2,6,20,21,1,19,7,8,10,11,12,13,9,17,16,15,14]);
              // [3,4,5,2,6,20,21,1,19,7,8,10,11,12,13,9,17,16,15,14]);
          function unscram(){
              emailScramble.initAnimatedBubbleSort();
              var elem = document.getElementById('covermail');
              elem.style.backgroundColor = 'yellow';
          }
          </script>

<p align>I am a Ph.D. student in the department of Computer Science at <a href="htts://www.jhu.edu"> Johns Hopkins University</a>, advised by <a href = "https://www.cs.jhu.edu/~raman">Raman Arora</a>. My research interest is, broadly, in the intersection of Machine Learning, Statistics and Optimization.
<!-- </p> -->
<!-- <p align> -->
  I graduated from <a href="https://www.iitk.ac.in/"> Indian Intitute of Technology Kanpur</a> with a Bachelors-Masters degree in Mathematics and Computing and minors in Computer Science and English Literature. At IIT Kanpur, I worked with <a href = "http://www.cse.iitk.ac.in/users/purushot/">Purushottam Kar</a>, <a href="http://home.iitk.ac.in/~kundu/kundu.html">Debasis Kundu</a> and  <a href = "http://prateekjain.org">Prateek Jain</a> </p>

<br>
               
               
<p align=center>
<a href="mailto:enayat@jhu.edu">Email</a> &nbsp/&nbsp
<a href="files/enayat_cv.pdf">CV</a> 
<!-- &nbsp/&nbsp <a href="https://www.twitter.com/EnayatUllah">Twitter</a> -->
<!-- <a href="http://github.com/EnayatUllah">Github</a> &nbsp/&nbsp -->
</p>
      </td>
              <td width="33%"><img class="image-cropper" src="img/photo.jpg"></td>
            </tr>
          </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
<tr>
<td>
<heading >News</heading>
<ul> 
	<li><em>Feb 2020.</em> &nbsp Paper on <a href="https://arxiv.org/abs/2002.09609"> Private Stochastic Convex Optimization</a> posted online.</li>
	<li><em>Jan-April 2020.</em> &nbsp Visting the Institute for Advanced Study, Princeton. </li>
	<li><em>Aug 2019.</em> &nbsp Paper on <a href="https://arxiv.org/abs/1808.00934"> distributed SGD </a> accepted at NeurIPS 2019.</li>
  <li><em>July 2019.</em> &nbsp Paper on <a href="https://arxiv.org/abs/1907.07574">  time-decay streams</a> accepted at <a href="https://approxconference.wordpress.com/"> APPROX 2019 </a>.</li>
  <!-- <li><em>Feb 2019.</em> &nbsp Paper on <a href="https://arxiv.org/abs/1808.00934"> distributed SGD </a>  posted online</li> -->
  <li><em>Aug 2018.</em> &nbsp Paper on <a href="https://arxiv.org/abs/1808.00934"> Streaming Kernel PCA </a> accepted at NeurIPS 2018.</li>

</ul>
</td>
</tr>





           <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <heading>Research</heading>
              </td>
            </tr>





<tr bgcolor="#ffffd0">
<td valign="top" width="100%">
<p><a href="">
<papertitle>Private Stochastic Convex Optimization: Efficient Algorithms for Non-smooth Objectives</papertitle></a>
<br>Raman Arora, Teodor V Marinov, <b>Enayat Ullah</b> <em>(\( \alpha\)-\(\beta\) order)</em> <br>
<!-- <em>To appear at APPROX 2019</em> -->
  <br> <a href = "https://arxiv.org/abs/2002.09609">arXiv</a>  &nbsp|&nbsp 
<a id ="show_private" >Show abstract</a><br>
<script type="text/javascript">
$(document).ready(function () {
    $("#show_private").click(function () {
        // var $this = $(this);
        $("#abstract_private").toggle();
         $(this).text(function(i, v){
       return v === 'Show abstract' ? 'Hide abstract' : 'Show abstract'
    });
    });
});
</script>
<div id="abstract_private" style="display:none">
In this paper, we revisit the problem of private stochastic convex optimization. We propose an algorithm based on noisy mirror descent, which achieves optimal rates both in terms of statistical complexity and number of queries to a first-order stochastic oracle in the regime when the privacy parameter is inversely proportional to the number of samples.
</div>
</p>
</td>
</tr>



<tr >
<td valign="top" width="100%">
<p><a href="">
<papertitle>Communication-efficient Distributed SGD with Sketching</papertitle></a>
<br>Nikita Ivkin, Daniel Rothchild, <b>Enayat Ullah</b>, Vladimir Braverman, Ion Stoica, Raman Arora<br>
<em>Published at NeurIPS 2019</em>
<br> <a href = "https://arxiv.org/abs/1808.00934">arXiv</a>  &nbsp|&nbsp 
<a href = "files/sketchSGD.pdf">pdf</a> &nbsp|&nbsp 
<a id ="show_sketch_sgd" >Show abstract</a><br>
<script type="text/javascript">
$(document).ready(function () {
    $("#show_sketch_sgd").click(function () {
        // var $this = $(this);
        $("#abstract_sketch_sgd").toggle();
         $(this).text(function(i, v){
       return v === 'Show abstract' ? 'Hide abstract' : 'Show abstract'
    });
    });
});
</script>
<div id="abstract_sketch_sgd" style="display:none">
<p>
Large-scale distributed training of neural networks is often limited by network bandwidth, wherein the communication time overwhelms the local computation time. Motivated by the success of sketching methods in sub-linear/streaming algorithms, we introduce Sketched-SGD, an algorithm for carrying out distributed SGD by communicating sketches instead of full gradients. We show that Sketched-SGD has favorable convergence rates on several classes of functions. When considering all communication -- both of gradients and of updated model weights -- Sketched-SGD reduces the amount of communication required compared to other gradient compression methods from $O(d)$ or $O(W)$ to $O(\log d)$, where $d$ is the number of model parameters and $W$ is the number of workers participating in training. We run experiments on a transformer model, an LSTM, and a residual network, demonstrating up to a 40x reduction in total communication cost with no loss in final model performance. We also show experimentally that Sketched-SGD scales to at least 256 workers without increasing communication cost or degrading model performance.
</p>
</div>
</td>
</tr>


<tr >
<td valign="top" width="100%">
<p><a href="">
<papertitle>Improved Algorithms for Time-Decay Streams</papertitle></a>
<br>Vladimir Braverman, Harry Lang, <b>Enayat Ullah</b>, Samson Zhou <em>(\( \alpha\)-\(\beta\) order)</em> <br>
<em>Published at APPROX 2019</em>
  <br> <a href = "https://arxiv.org/abs/1808.00934">arXiv</a>  &nbsp|&nbsp 
<a id ="show_time_decay" >Show abstract</a><br>
<script type="text/javascript">
$(document).ready(function () {
    $("#show_time_decay").click(function () {
        // var $this = $(this);
        $("#abstract_time_decay").toggle();
         $(this).text(function(i, v){
       return v === 'Show abstract' ? 'Hide abstract' : 'Show abstract'
    });
    });
});
</script>
<div id="abstract_time_decay" style="display:none">
  In the time-decay model for data streams, elements of an underlying data set arrive sequentially with the recently arrived elements being more important. 
  We provide a general framework that takes any offline-coreset and gives a time-decay coreset for polynomial time decay functions. 
We also consider the exponential time decay model for k-median clustering, where we provide a constant factor approximation algorithm that utilizes the online facility location algorithm. Our algorithm stores $O(k\log(h\Delta)+h)$ points where $h$ is the half-life of the decay function and $\Delta$ is the aspect ratio of the dataset. Our techniques extend to k-means clustering and M-estimators as well.
</div>
</p>
</td>
</tr>

<tr>
<td valign="top" width="100%">
<p><a href="">
<papertitle>Streaming Kernel PCA with \(\tilde O(\sqrt{n})\) Random Features</papertitle></a>
<!-- <br><span class="highlight">Enayat Ullah</span>, Poorya Mianjy, Teodor V Marinov, Raman Arora<br> -->
<br><b>Enayat Ullah</b>, Poorya Mianjy, Teodor V Marinov, Raman Arora<br>
<em>Published at NuerIPS 2018 </em>
<br> <a href = "https://arxiv.org/abs/1808.00934">arXiv</a>  &nbsp|&nbsp 
<a id ="show_kernel_pca" >Show abstract</a><br>
<script type="text/javascript">
$(document).ready(function () {
    $("#show_kernel_pca").click(function () {
        // var $this = $(this);
        $("#abstract_kernel_pca").toggle();
         $(this).text(function(i, v){
       return v === 'Show abstract' ? 'Hide abstract' : 'Show abstract'
    });
    });
});
</script>
<div id="abstract_kernel_pca" style="display:none">
<p>We study the statistical and computational aspects of kernel principal component analysis using random Fourier features and show that under mild assumptions, $ O(\sqrt{n}\log n)$ features suffices to achieve $O(1/\epsilon^2)$ sample complexity. Furthermore, we give a memory efficient streaming algorithm based on classical Oja's algorithm that achieves this rate.</p>
</div>
</td>

</tr>




<!-- <tr >
<td valign="top" width="100%">
<p><a href="">
<papertitle>Clustering with Approximate Nearest Neighbour Oracles</papertitle></a>
<br><b>Enayat Ullah</b>, Harry Lang, Raman Arora, Vladimir Braverman<br>
<em>(Under Submission)</em>
</td>
</tr>

<tr >
<td valign="top" width="100%">
<p><a href="">
<papertitle>Generalization properties of Kernel Canonical Correlation Analysis</papertitle></a>
<br><b>Enayat Ullah</b>, Raman Arora<br>
<em>(Under Submission)</em>
</td>
</tr> -->



<!-- <tr >
<td valign="top" width="100%">
<p><a href="">
<papertitle>Convergence Guarantees for ADAM and RMSProp in Non-Convex Optimization ..</papertitle></a>
<br><em>(\( \alpha\)-\(\beta\) order)</em> Amitabh Basu, Soham De, Anirbit Mukherjee, <b>Enayat Ullah</b><br> 
<em>(Under Submission)</em>
<br> <a href = "https://arxiv.org/abs/1807.06766v1">arXiv</a> <br>
</td>
</tr>
<tr> -->
<td>
<br>
<p align="right"><font size="2">
<a href="http://www.cs.berkeley.edu/~barron/">website</a>
<a href="http://i-am-karan-singh.github.io/"> credits</a>
</font>
</p>
</td>
</tr>           
</table>
</body>


</html>


